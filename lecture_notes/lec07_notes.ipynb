{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0001 Lecture 7: Testing, Debugging, Exceptions, and Assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Speaker:** Dr. Ana Bell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim for High Quality - Analogy with Soup\n",
    "You are making soup but bugs keep falling into soup from ceiling. What do you do?\n",
    "- check soup for bugs\n",
    "    - testing\n",
    "- keep lid closed\n",
    "    - defensive programming\n",
    "- clean kitchen\n",
    "    - eliminate source of bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Defensive Programming**\n",
    "    - write **specifications** for functions\n",
    "    - **modularize** programs\n",
    "    - check **conditions** on inputs/outputs (assertions)\n",
    "- **Testing/Validation**\n",
    "    - **compare** input/output pairs to specification\n",
    "    - \"It's not working!\"\n",
    "    - \"How can I break my program?\"\n",
    "- **Debugging**\n",
    "    - **study events** leading up to an error\n",
    "    - \"Why is it not working?\"\n",
    "    - \"How can I fix my program?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Yourself up for Easy Testing and Debugging\n",
    "- from the **start**, design code to ease this part\n",
    "- break program up into **modules** that can be tested and debugged individually\n",
    "- **document constraints** on modules\n",
    "    - what do you expect the input to be?\n",
    "    - what do you expect the output to be?\n",
    "- **document assumptions** behind code design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When are you ready to test?\n",
    "- ensure **code runs**\n",
    "    - remove syntax errors\n",
    "    - remove static semantic errors\n",
    "    - Python interpreter can usually find these for you\n",
    "- have a **set of expected results**\n",
    "    - an input set\n",
    "    - for each input, the expected output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes of Tests\n",
    "- **Unit testing**\n",
    "    - validate each piece of the program\n",
    "    - **testing each function** separately\n",
    "- **Regression testing**\n",
    "    - add test for bugs as you find them\n",
    "    - **catch reintroduced** errors that were previously fixed\n",
    "- **Integration testing**\n",
    "    - does **overall program** work?\n",
    "    - tend to rush to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Approaches\n",
    "- **intuition** about natural boundaries to the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bigger(x,y):\n",
    "    \"\"\"Assumes x and y are ints\n",
    "    Returns True if y is less than x, else False\"\"\"\n",
    "    return y < x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- come up with some natural partitions?\n",
    "- if no natural partitions, might do **random testing**\n",
    "    - probability that code is correct increases with more tests\n",
    "    - better options below\n",
    "- **black box testing**\n",
    "    - explore paths through specification\n",
    "- **glass box testing**\n",
    "    - explore paths through some code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Box Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt(x, eps):\n",
    "    \"\"\"Assumes x, eps floats, x >= 0, eps > 0\n",
    "    Returns res such that x-eps <= res*res <= x+eps\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- designed **without looking** at the code\n",
    "- can be done by someone other than the implementer to avoid some implementer **biases**\n",
    "- testing can be **reused** if implementation changes\n",
    "- **paths** through specification\n",
    "    - build test cases in different natural space partitions\n",
    "    - also consider boundary conditions (empty lists, singleton list, large numbers, small numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cases for sqrt:\n",
    "    - boundary: x = 0, eps = 0.0001\n",
    "    - perfect square: x = 25, eps = 0.0001\n",
    "    - less than 1: x = 0.05, eps = 0.0001\n",
    "    - irrational square root: x = 2, eps = 0.0001\n",
    "    - extremes: x = 2, eps = 1.0/2.0 ** 64.0\n",
    "    - extremes: x = 2.0 ** 64.0, eps = 2.0 ** 64.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass Box Testing\n",
    "- **use code** directly to guide design of test cases\n",
    "- called **path-complete** if every potential path through code is tested at least once\n",
    "- what are some **drawbacks** of this type of testing?\n",
    "    - can go through loops arbitrarily many times\n",
    "    - missing paths\n",
    "- guidelines\n",
    "    - branches (exercise all parts of a conditional)\n",
    "    - for loops (loop not entered, body of loop executed exactly once, body of loop executed more than once)\n",
    "    - while loops (same as for loops, cases that catch all ways to exit loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs(x):\n",
    "    \"\"\" Assumes x is an int\n",
    "    Returns x if x >= 0 and -x otherwise\"\"\"\n",
    "    if x < -1: \n",
    "        return -x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a path-complete test suite could **miss a bug**\n",
    "- path-complete test suite: 2 and -2\n",
    "- but abs(-1) incorrectly returns -1\n",
    "- should still test boundary cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "- steep learing curve\n",
    "- goal is to have a bug-free program\n",
    "- tools\n",
    "    - **built in** to IDLE and Anaconda\n",
    "    - **Python tutor**\n",
    "    - print statement\n",
    "    - use your brain, be **systematic** in your hunt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Statements\n",
    "- good way to **test hypothesis**\n",
    "- when to print\n",
    "    - enter function\n",
    "    - parameters\n",
    "    - function results\n",
    "- use **bisection method**\n",
    "    - put print halfway in code\n",
    "    - decide where bug may be depending on values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Steps\n",
    "- **study** program code\n",
    "    - don't ask what is wrong\n",
    "    - ask how did I get the unexpected result\n",
    "    - is it part of a family?\n",
    "- **scientific method**\n",
    "    - study available data\n",
    "    - form hypothesis\n",
    "    - repeatable experiments\n",
    "    - pick simplest input to test with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Messages -- Easy\n",
    "- trying to access beyond the limits of a list\n",
    "    - test = [1, 2, 3] then test[4] --> IndexError\n",
    "- trying to convert an inappropriate type\n",
    "    - int(test) --> TypeError\n",
    "- referencing a non-existent variable\n",
    "    - a --> NameError\n",
    "- forgetting to close parenthesis, quotation, etc.\n",
    "    - a = len([1,2,3]\n",
    "    - print(a) --> SyntaxError\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Errors -- Hard\n",
    "- **think** before writing new code\n",
    "- **draw** pictures, take a break\n",
    "- **explain** the code to\n",
    "    - someone else\n",
    "    - a rubber ducky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do's and Dont's\n",
    "- Don't:\n",
    "    - write the entire program\n",
    "    - test the entire program\n",
    "    - debug entire program\n",
    "- Do:\n",
    "    - write a function\n",
    "    - test the function, debug the function\n",
    "    - write a function\n",
    "    - test the function, debug the function\n",
    "    - do integration testing\n",
    "- Don't:\n",
    "    - change code\n",
    "    - remember where bug was\n",
    "    - test code\n",
    "    - forget where bug was or what change you made\n",
    "    - panic\n",
    "- Do:\n",
    "    - backup code\n",
    "    - change code\n",
    "    - write down potential bug in a comment\n",
    "    - test code\n",
    "    - compare new version with old version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptions and Assertions\n",
    "- what happens when procedure execution hits an **unexpected condition**?\n",
    "- get an **exception**... to what was expected\n",
    "    - trying to access beyond list limits\n",
    "    - tryng to convert an inappropriate type\n",
    "    - referencing a non-existing variable\n",
    "    - mixing data types without coercion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types of exceptions\n",
    "- already seen common error types:\n",
    "    - SyntaxError\n",
    "    - NameError\n",
    "    - AttributeError\n",
    "    - TypeError\n",
    "    - ValueError\n",
    "    - IOError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Exceptions\n",
    "- Python code can provide **handlers** for exceptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me one number:'a'\n",
      "Bug in user input.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a = int(input(\"Tell me one number:\"))\n",
    "    b = int(input(\"Tell me another number:\"))\n",
    "    print(\"a/b =\", a/b)\n",
    "except:\n",
    "    print(\"Bug in user input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exceptions **raised** by any statement in body of **try** are **handled** by the **except** statement and execution continues with the body of the *except* statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Specific Exceptions\n",
    "- have **separate except caluses** to deal with a particular type of exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me one number:a\n",
      "Could not convert to a number.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a = int(input(\"Tell me one number:\"))\n",
    "    b = int(input(\"Tell me another number:\"))\n",
    "    print(\"a/b =\", a/b)\n",
    "    print(\"a+b =\", a+b)\n",
    "# only execute if these errors come up\n",
    "except ValueError:\n",
    "    print(\"Could not convert to a number.\")\n",
    "except ZeroDivisionError:\n",
    "    print(\"Can't divide by zero\")\n",
    "except:\n",
    "    print(\"Something went very wrong.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Exceptions\n",
    "- else:\n",
    "    - body of this is executed when execution of associated *try* body **completes with no exceptions**\n",
    "- finally:\n",
    "    - body of this is **always executed** after *try*, *else* and *except* clauses, even if they raised another error or executed a *break*, *continue* or *return*\n",
    "    - useful for clean-up code that should be run no matter what else happened (e.g. close a file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do with exceptions?**\n",
    "- what to do when encounter an error?\n",
    "- **fail silently**:\n",
    "    - substitute default values or just continue\n",
    "    - bad idea! user gets no warning\n",
    "- return an **\"error\" value**\n",
    "    - what value to choose?\n",
    "    - complicates code having to check for a special value\n",
    "- stop execution, **signal error** condition\n",
    "    - in Python: **raise an exception**\n",
    "    - raise Exception(\"descriptive string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exception as Control Flow\n",
    "- don't return special values when an error occurred and then check whether 'error value' was returned\n",
    "- instead, **raise an excecption** when unable to produce a result consistent with the function's specifications\n",
    "- raise (exceptionName)(arguments)\n",
    "- raise ValueError(\"something is wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Raising an Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratios(L1, L2):\n",
    "    \"\"\" Assumes: L1 and L2 are lists of equal length of numbers\n",
    "        Returns: a list containing L1[i]/L2[i] \"\"\"\n",
    "    ratios = []\n",
    "    for index in range(len(L1)):\n",
    "        try:\n",
    "            ratios.append(L1[index]/L2[index])\n",
    "        except ZeroDivisionError:\n",
    "            ratios.append(float('nan')) #nan = not a number\n",
    "        except:\n",
    "            # manage flow of program by raising own error\n",
    "            raise ValueError('get_ratios called with bad arg')\n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Exceptions\n",
    "- assume we are **given a list** for a subjectL each entry is a list of two parts\n",
    "    - a list of first and last name for a student\n",
    "    - a list of grades on assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grades = [[['peter', 'parker'], [80.0, 70.0, 85.0]],\n",
    "                [['bruce', 'wayne'], [100.0, 80.0, 74.0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a **new class list**, with name, grades, and an average\n",
    "\n",
    "[[['peter', 'parker'], [80.0, 70.0, 85.0], 78.33333],\n",
    "[['bruce', 'wayne'], [100.0, 80.0, 74.0], 84.666667]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example code\n",
    "\n",
    "def get_stats(class_list):\n",
    "    new_stats = []\n",
    "    for elt in class_list:\n",
    "        new_stats.append([elt[0], elt[1], avg(elt[1])])\n",
    "    return new_stats\n",
    "\n",
    "def avg(grades):\n",
    "    return sum(grades)/len(grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error if no grade for a student\n",
    "- if one or more students **don't have any grades**, get an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grades = [[['peter', 'parker'], [10.0, 5.0, 85.0]],\n",
    "                [['bruce', 'wayne'], [10.0, 8.0, 74.0]],\n",
    "                [['captain', 'america'], [8.0,10.0,96.0]],\n",
    "                [['deadpool'], []]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get *ZeroDivisionError: float division by zero* because try to return sum(grades)/len(grades), length is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Flag the Error by printing a message\n",
    "- decide to **notify** that something went wrong with a msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(grades):\n",
    "    try:\n",
    "        return sum(grades)/len(grades)\n",
    "    except ZeroDivisionError:\n",
    "        print('warning: no grades data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- running on some test data gives *warning: no grades data*\n",
    "    - flagged the error\n",
    "    - [['deadpool'], [], None]] # None because avg did not return anything in the except"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Change the policy\n",
    "- decide that a student with no grades gets a zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(grades):\n",
    "    try:\n",
    "        return sum(grades)/len(grades)\n",
    "    except ZeroDivisionError:\n",
    "        print('warning: no grades data')\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- running on some test data gives *warning: no grades data*\n",
    "    - still flagged the error\n",
    "    - [['deadpool'], [], 0.0]] #now avg returns 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assertions\n",
    "- want to be sure that **assumptions** on state of computation are as expected\n",
    "- use an **assert statement** to raise an *AssertionError* exception if assumptions not met\n",
    "- an example of good **defensive programming**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(grades):\n",
    "    assert len(grades) != 0, 'no grades data'\n",
    "    # function ends immediately if assertion not met\n",
    "    return sum(grades)/len(grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- raises an *AssertionError* if it is given an empty list for grades\n",
    "- otherwise runs ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "no grades data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f651860dca62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-f32a19ef8935>\u001b[0m in \u001b[0;36mavg\u001b[1;34m(grades)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'no grades data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# function ends immediately if assertion not met\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrades\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: no grades data"
     ]
    }
   ],
   "source": [
    "print(avg([])) # will raise the assertion error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assertions as Defensive Programming\n",
    "- assertions don't allow a programmer to control response to unexpected conditions\n",
    "- ensure that **execution halts** whenever an unexpected condition is not met\n",
    "- typically used to **check inputs** to functions, but can be used anywhere\n",
    "- can be used to **check ouputs** of a function to avoid propagating bad values\n",
    "- can make it easier to locate a source of a bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to use Assertions?\n",
    "- goal is to spot bugs as soon as introduced and make clear where they happened\n",
    "- use as a **supplement** to testing\n",
    "- raise **exceptions** if user supplies **bad data input**\n",
    "- use **assertions** to\n",
    "    - check **types** of arguments or values\n",
    "    - check that **invariants** on data structures are met\n",
    "    - check **constraints** on return values\n",
    "    - check **constraints** on return values\n",
    "    - check for **violations** of constraints on procedure (e.g. no duplicates in a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
